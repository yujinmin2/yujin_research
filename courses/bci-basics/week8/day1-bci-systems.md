---
title: "W8D1 - BCI Systems"
subtitle: "ì‹¤ìš©ì ì¸ BCI ì‹œìŠ¤í…œ ì„¤ê³„ì™€ êµ¬í˜„"
---

# W8D1: BCI Systems

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yujinmin2/yujin_research/blob/main/notebooks/W8D1_BCISystems.ipynb)

---

## ğŸ“‹ Overview

ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ëª¨ë“  ê²ƒì„ í†µí•©í•˜ì—¬ **ì‹¤ì œ BCI ì‹œìŠ¤í…œ**ì„ ì„¤ê³„í•©ë‹ˆë‹¤.

```{mermaid}
flowchart TB
    subgraph ì‹ í˜¸íšë“
        EEG[EEG]
        ECOG[ECoG]
        SPIKE[Intracortical]
    end
    
    subgraph ì „ì²˜ë¦¬
        FILT[í•„í„°ë§]
        ART[ì•„í‹°íŒ©íŠ¸ ì œê±°]
        REF[ì°¸ì¡° ì„ íƒ]
    end
    
    subgraph íŠ¹ì§•ì¶”ì¶œ
        TIME[ì‹œê°„ íŠ¹ì§•]
        FREQ[ì£¼íŒŒìˆ˜ íŠ¹ì§•]
        SPACE[ê³µê°„ íŠ¹ì§•]
    end
    
    subgraph ë¶„ë¥˜/íšŒê·€
        SVM[SVM]
        LDA[LDA]
        DL[Deep Learning]
    end
    
    subgraph ì¶œë ¥
        CURSOR[ì»¤ì„œ ì œì–´]
        SPELL[íƒ€ì´í•‘]
        ROBOT[ë¡œë´‡íŒ”]
    end
    
    EEG --> FILT
    ECOG --> FILT
    SPIKE --> FILT
    FILT --> ART --> REF
    REF --> TIME
    REF --> FREQ
    REF --> SPACE
    TIME --> SVM
    FREQ --> LDA
    SPACE --> DL
    SVM --> CURSOR
    LDA --> SPELL
    DL --> ROBOT
```

---

## ğŸ¯ Learning Objectives

1. **BCI íŒŒì´í”„ë¼ì¸** ì „ì²´ ì´í•´
2. **EEG ì „ì²˜ë¦¬** êµ¬í˜„
3. **íŠ¹ì§• ì¶”ì¶œ** ê¸°ë²• ì ìš©
4. **ì‹¤ì‹œê°„ ë¶„ë¥˜** ì‹œìŠ¤í…œ êµ¬í˜„

---

## 1. BCI ì‹œìŠ¤í…œ ìœ í˜•

### 1.1 ë¶„ë¥˜

| ìœ í˜• | ì‹ í˜¸ | ì¹¨ìŠµì„± | ì‘ìš© |
|------|------|--------|------|
| **Motor Imagery** | EEG | ë¹„ì¹¨ìŠµ | íœ ì²´ì–´, ì»¤ì„œ |
| **P300 Speller** | EEG | ë¹„ì¹¨ìŠµ | íƒ€ì´í•‘ |
| **SSVEP** | EEG | ë¹„ì¹¨ìŠµ | ì„ íƒ ì¸í„°í˜ì´ìŠ¤ |
| **ECoG BCI** | ECoG | ë°˜ì¹¨ìŠµ | ê³ ì„±ëŠ¥ ì œì–´ |
| **Intracortical** | Spikes | ì¹¨ìŠµ | ë¡œë´‡íŒ”, ìŒì„± |

### 1.2 ì‹ í˜¸ íŠ¹ì„± ë¹„êµ

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal

def compare_signals():
    """ë‹¤ì–‘í•œ BCI ì‹ í˜¸ íŠ¹ì„± ì‹œë®¬ë ˆì´ì…˜"""
    
    fig, axes = plt.subplots(3, 2, figsize=(14, 10))
    fs = 1000  # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜
    duration = 2
    t = np.arange(0, duration, 1/fs)
    
    # EEG ì‹œë®¬ë ˆì´ì…˜
    np.random.seed(42)
    eeg = (10 * np.sin(2 * np.pi * 10 * t) +  # Alpha
           5 * np.sin(2 * np.pi * 22 * t) +   # Beta
           20 * np.random.randn(len(t)))       # Noise
    
    axes[0, 0].plot(t, eeg, 'b-', linewidth=0.5)
    axes[0, 0].set_title('EEG (Scalp)\nSNR: Low, Resolution: ~cm')
    axes[0, 0].set_ylabel('Amplitude (Î¼V)')
    axes[0, 0].set_ylim(-100, 100)
    
    # EEG ìŠ¤í™íŠ¸ëŸ¼
    f, psd = signal.welch(eeg, fs, nperseg=512)
    axes[0, 1].semilogy(f, psd, 'b-')
    axes[0, 1].set_xlim(0, 50)
    axes[0, 1].set_xlabel('Frequency (Hz)')
    axes[0, 1].set_ylabel('PSD')
    axes[0, 1].axvspan(8, 13, alpha=0.3, color='yellow', label='Alpha')
    axes[0, 1].axvspan(13, 30, alpha=0.3, color='green', label='Beta')
    axes[0, 1].legend()
    
    # ECoG ì‹œë®¬ë ˆì´ì…˜
    ecog = (50 * np.sin(2 * np.pi * 10 * t) +
            30 * np.sin(2 * np.pi * 70 * t) +  # Gamma
            10 * np.random.randn(len(t)))
    
    axes[1, 0].plot(t, ecog, 'g-', linewidth=0.5)
    axes[1, 0].set_title('ECoG (Cortical Surface)\nSNR: Medium, Resolution: ~mm')
    axes[1, 0].set_ylabel('Amplitude (Î¼V)')
    axes[1, 0].set_ylim(-200, 200)
    
    # ECoG ìŠ¤í™íŠ¸ëŸ¼
    f, psd = signal.welch(ecog, fs, nperseg=512)
    axes[1, 1].semilogy(f, psd, 'g-')
    axes[1, 1].set_xlim(0, 150)
    axes[1, 1].axvspan(30, 100, alpha=0.3, color='red', label='High Gamma')
    axes[1, 1].legend()
    
    # Intracortical ì‹œë®¬ë ˆì´ì…˜
    spike_times = np.sort(np.random.uniform(0, duration, 60))
    intracortical = np.zeros(len(t))
    for st in spike_times:
        idx = int(st * fs)
        if idx < len(t) - 20:
            # ìŠ¤íŒŒì´í¬ íŒŒí˜•
            spike = 100 * np.exp(-np.arange(20) / 2) * np.sin(np.arange(20) * 0.5)
            intracortical[idx:idx+20] += spike
    intracortical += 5 * np.random.randn(len(t))
    
    axes[2, 0].plot(t, intracortical, 'r-', linewidth=0.5)
    axes[2, 0].set_title('Intracortical (Single Unit)\nSNR: High, Resolution: ~Î¼m')
    axes[2, 0].set_xlabel('Time (s)')
    axes[2, 0].set_ylabel('Amplitude (Î¼V)')
    
    # ìŠ¤íŒŒì´í¬ ë˜ìŠ¤í„°
    axes[2, 1].eventplot(spike_times, linewidths=1.5)
    axes[2, 1].set_xlim(0, duration)
    axes[2, 1].set_xlabel('Time (s)')
    axes[2, 1].set_title(f'Spike Raster ({len(spike_times)/duration:.0f} Hz)')
    
    plt.tight_layout()
    plt.show()

compare_signals()
```

---

## 2. EEG ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### 2.1 ì „ì²´ íë¦„

```{mermaid}
flowchart LR
    RAW[Raw EEG] --> BP[ë°´ë“œíŒ¨ìŠ¤ í•„í„°<br/>0.5-40 Hz]
    BP --> NOTCH[ë…¸ì¹˜ í•„í„°<br/>50/60 Hz]
    NOTCH --> REF[ì°¸ì¡° ì¬ì„¤ì •<br/>CAR/Laplacian]
    REF --> ART[ì•„í‹°íŒ©íŠ¸ ì œê±°<br/>ICA/ì„ê³„ê°’]
    ART --> EPOCH[ì—í¬í‚¹]
    EPOCH --> FEAT[íŠ¹ì§• ì¶”ì¶œ]
```

### 2.2 êµ¬í˜„

```python
from scipy.signal import butter, filtfilt, iirnotch

class EEGPreprocessor:
    def __init__(self, fs=250):
        self.fs = fs
    
    def bandpass_filter(self, data, low=0.5, high=40, order=4):
        """ë°´ë“œíŒ¨ìŠ¤ í•„í„°"""
        nyq = self.fs / 2
        b, a = butter(order, [low/nyq, high/nyq], btype='band')
        return filtfilt(b, a, data, axis=-1)
    
    def notch_filter(self, data, freq=60, Q=30):
        """ë…¸ì¹˜ í•„í„° (ì „ì›ì„  ë…¸ì´ì¦ˆ ì œê±°)"""
        b, a = iirnotch(freq, Q, self.fs)
        return filtfilt(b, a, data, axis=-1)
    
    def common_average_reference(self, data):
        """ê³µí†µ í‰ê·  ì°¸ì¡° (CAR)"""
        return data - np.mean(data, axis=0)
    
    def artifact_rejection(self, data, threshold=100):
        """ì„ê³„ê°’ ê¸°ë°˜ ì•„í‹°íŒ©íŠ¸ ì œê±°"""
        mask = np.max(np.abs(data), axis=-1) < threshold
        return data[mask], mask
    
    def process(self, data):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        data = self.bandpass_filter(data)
        data = self.notch_filter(data)
        data = self.common_average_reference(data)
        return data

# ì˜ˆì‹œ
np.random.seed(42)
fs = 250
duration = 10
n_channels = 8
t = np.arange(0, duration, 1/fs)

# ì‹œë®¬ë ˆì´ì…˜ EEG (ì‹ í˜¸ + ë…¸ì´ì¦ˆ + ì•„í‹°íŒ©íŠ¸)
raw_eeg = np.zeros((n_channels, len(t)))
for ch in range(n_channels):
    # ì‹ í˜¸
    raw_eeg[ch] = 10 * np.sin(2 * np.pi * 10 * t + np.random.rand() * 2 * np.pi)
    # ë…¸ì´ì¦ˆ
    raw_eeg[ch] += 5 * np.random.randn(len(t))
    # ì „ì›ì„  ë…¸ì´ì¦ˆ
    raw_eeg[ch] += 3 * np.sin(2 * np.pi * 60 * t)

# ì „ì²˜ë¦¬
preprocessor = EEGPreprocessor(fs=fs)
processed_eeg = preprocessor.process(raw_eeg)

# ë¹„êµ
fig, axes = plt.subplots(2, 2, figsize=(14, 8))

# Raw EEG
axes[0, 0].plot(t[:500], raw_eeg[0, :500], 'b-', linewidth=0.5)
axes[0, 0].set_title('Raw EEG (Channel 1)')
axes[0, 0].set_ylabel('Amplitude (Î¼V)')

# Processed EEG
axes[0, 1].plot(t[:500], processed_eeg[0, :500], 'g-', linewidth=0.5)
axes[0, 1].set_title('Processed EEG')

# Raw ìŠ¤í™íŠ¸ëŸ¼
f, psd = signal.welch(raw_eeg[0], fs, nperseg=256)
axes[1, 0].semilogy(f, psd, 'b-')
axes[1, 0].set_xlabel('Frequency (Hz)')
axes[1, 0].set_ylabel('PSD')
axes[1, 0].set_title('Raw Spectrum')
axes[1, 0].axvline(x=60, color='red', linestyle='--', label='60Hz noise')
axes[1, 0].legend()

# Processed ìŠ¤í™íŠ¸ëŸ¼
f, psd = signal.welch(processed_eeg[0], fs, nperseg=256)
axes[1, 1].semilogy(f, psd, 'g-')
axes[1, 1].set_xlabel('Frequency (Hz)')
axes[1, 1].set_title('Processed Spectrum')
axes[1, 1].axvline(x=60, color='red', linestyle='--')

plt.tight_layout()
plt.show()
```

---

## 3. íŠ¹ì§• ì¶”ì¶œ

### 3.1 ì£¼ìš” íŠ¹ì§•

| ë„ë©”ì¸ | íŠ¹ì§• | ìš©ë„ |
|--------|------|------|
| **ì‹œê°„** | í‰ê· , ë¶„ì‚°, Zero-crossing | ì¼ë°˜ |
| **ì£¼íŒŒìˆ˜** | Band power, PSD | Motor Imagery |
| **ì‹œê³µê°„** | CSP, ì½”íˆì–´ëŸ°ìŠ¤ | Motor Imagery |
| **ERP** | P300 ì§„í­/ì§€ì—° | P300 Speller |

### 3.2 Band Power ì¶”ì¶œ

```python
def extract_band_powers(data, fs=250):
    """ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ íŒŒì›Œ ì¶”ì¶œ"""
    bands = {
        'delta': (0.5, 4),
        'theta': (4, 8),
        'alpha': (8, 13),
        'beta': (13, 30),
        'gamma': (30, 45)
    }
    
    features = {}
    for band_name, (low, high) in bands.items():
        # ë°´ë“œíŒ¨ìŠ¤ í•„í„°
        nyq = fs / 2
        b, a = butter(4, [low/nyq, high/nyq], btype='band')
        filtered = filtfilt(b, a, data, axis=-1)
        # íŒŒì›Œ ê³„ì‚°
        power = np.mean(filtered**2, axis=-1)
        features[band_name] = power
    
    return features

# Motor Imagery íŠ¹ì§• ì¶”ì¶œ ì˜ˆì‹œ
def motor_imagery_features(eeg_left, eeg_right, fs=250):
    """ì¢Œìš° ìš´ë™ ìƒìƒ ë¶„ë¥˜ë¥¼ ìœ„í•œ íŠ¹ì§•"""
    
    # ê° ì¡°ê±´ì˜ ëŒ€ì—­ íŒŒì›Œ
    feat_left = extract_band_powers(eeg_left, fs)
    feat_right = extract_band_powers(eeg_right, fs)
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    x = np.arange(len(feat_left))
    width = 0.35
    
    # C3 ì±„ë„ (ì™¼ìª½ ìš´ë™í”¼ì§ˆ)
    axes[0].bar(x - width/2, [feat_left[b][0] for b in feat_left], width, 
                label='Left Hand MI', color='blue', alpha=0.7)
    axes[0].bar(x + width/2, [feat_right[b][0] for b in feat_right], width,
                label='Right Hand MI', color='red', alpha=0.7)
    axes[0].set_xticks(x)
    axes[0].set_xticklabels(list(feat_left.keys()))
    axes[0].set_ylabel('Power')
    axes[0].set_title('C3 (Left Motor Cortex)')
    axes[0].legend()
    
    # C4 ì±„ë„ (ì˜¤ë¥¸ìª½ ìš´ë™í”¼ì§ˆ)
    axes[1].bar(x - width/2, [feat_left[b][1] for b in feat_left], width,
                label='Left Hand MI', color='blue', alpha=0.7)
    axes[1].bar(x + width/2, [feat_right[b][1] for b in feat_right], width,
                label='Right Hand MI', color='red', alpha=0.7)
    axes[1].set_xticks(x)
    axes[1].set_xticklabels(list(feat_left.keys()))
    axes[1].set_title('C4 (Right Motor Cortex)')
    axes[1].legend()
    
    plt.tight_layout()
    plt.show()

# ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
np.random.seed(42)
fs = 250
n_samples = fs * 2

# ì™¼ì† ìƒìƒ â†’ C4 mu ê°ì†Œ
eeg_left = np.zeros((2, n_samples))
eeg_left[0] = 10 * np.sin(2 * np.pi * 10 * np.arange(n_samples)/fs)  # C3 ì •ìƒ
eeg_left[1] = 5 * np.sin(2 * np.pi * 10 * np.arange(n_samples)/fs)   # C4 ê°ì†Œ (ERD)
eeg_left += 3 * np.random.randn(2, n_samples)

# ì˜¤ë¥¸ì† ìƒìƒ â†’ C3 mu ê°ì†Œ
eeg_right = np.zeros((2, n_samples))
eeg_right[0] = 5 * np.sin(2 * np.pi * 10 * np.arange(n_samples)/fs)  # C3 ê°ì†Œ (ERD)
eeg_right[1] = 10 * np.sin(2 * np.pi * 10 * np.arange(n_samples)/fs) # C4 ì •ìƒ
eeg_right += 3 * np.random.randn(2, n_samples)

motor_imagery_features(eeg_left, eeg_right)
```

---

## 4. ì‹¤ì‹œê°„ BCI ì‹œìŠ¤í…œ

### 4.1 ì„¤ê³„ ê³ ë ¤ì‚¬í•­

| ìš”ì†Œ | ê³ ë ¤ì‚¬í•­ |
|------|----------|
| **ì§€ì—°** | 200ms ì´í•˜ ê¶Œì¥ |
| **ì •í™•ë„** | 70% ì´ìƒ í•„ìš” |
| **ì ì‘** | ì‚¬ìš©ì/ì„¸ì…˜ ë³€ë™ |
| **í”¼ë“œë°±** | í•™ìŠµì— ì¤‘ìš” |

### 4.2 ê°„ë‹¨í•œ ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ

```python
class SimpleBCI:
    def __init__(self, fs=250, n_channels=8, window_size=1.0):
        self.fs = fs
        self.n_channels = n_channels
        self.window_samples = int(window_size * fs)
        self.buffer = np.zeros((n_channels, self.window_samples))
        self.preprocessor = EEGPreprocessor(fs)
        self.classifier = None  # í•™ìŠµëœ ë¶„ë¥˜ê¸°
    
    def update_buffer(self, new_data):
        """ìƒˆ ë°ì´í„°ë¡œ ë²„í¼ ì—…ë°ì´íŠ¸ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)"""
        n_new = new_data.shape[1]
        self.buffer = np.roll(self.buffer, -n_new, axis=1)
        self.buffer[:, -n_new:] = new_data
    
    def extract_features(self):
        """í˜„ì¬ ë²„í¼ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        processed = self.preprocessor.process(self.buffer)
        features = extract_band_powers(processed, self.fs)
        # ë²¡í„°ë¡œ ë³€í™˜
        feat_vector = np.concatenate([features[b] for b in features])
        return feat_vector
    
    def predict(self):
        """ì‹¤ì‹œê°„ ì˜ˆì¸¡"""
        if self.classifier is None:
            return None
        features = self.extract_features()
        return self.classifier.predict([features])[0]
    
    def simulate_realtime(self, data, labels, chunk_size=25):
        """ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜"""
        predictions = []
        true_labels = []
        
        for i in range(0, data.shape[1] - chunk_size, chunk_size):
            chunk = data[:, i:i+chunk_size]
            self.update_buffer(chunk)
            
            if i >= self.window_samples:
                pred = self.predict()
                if pred is not None:
                    predictions.append(pred)
                    # í•´ë‹¹ ì‹œì ì˜ ë¼ë²¨ (ê°„ë‹¨í™”)
                    true_labels.append(labels[min(i // self.window_samples, len(labels)-1)])
        
        return predictions, true_labels

print("ì‹¤ì‹œê°„ BCI ì‹œìŠ¤í…œ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ")
print("ì‹¤ì œ ì‚¬ìš© ì‹œ: classifierë¥¼ í•™ìŠµì‹œí‚¨ í›„ simulate_realtime() í˜¸ì¶œ")
```

---

## 5. ì„±ëŠ¥ í‰ê°€

### 5.1 ì£¼ìš” ì§€í‘œ

| ì§€í‘œ | ìˆ˜ì‹ | ì˜ë¯¸ |
|------|------|------|
| **ì •í™•ë„** | $\frac{TP+TN}{Total}$ | ì „ì²´ ì •í™•ë„ |
| **ITR** | $\frac{60}{T}[log_2N + P log_2P + (1-P)log_2\frac{1-P}{N-1}]$ | ì •ë³´ ì „ì†¡ë¥  |
| **Cohen's Îº** | $\frac{Acc - Chance}{1 - Chance}$ | ìš°ì—° ë³´ì • ì •í™•ë„ |

---

## ğŸ“ ì‹¤ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: CSP êµ¬í˜„
Common Spatial Patterns ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ì„¸ìš”.

### ë¬¸ì œ 2: ì˜¨ë¼ì¸ ì ì‘
ì„¸ì…˜ ê°„ ë³€ë™ì— ì ì‘í•˜ëŠ” ë¶„ë¥˜ê¸°ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

### ë¬¸ì œ 3: í”¼ë“œë°± ì‹œìŠ¤í…œ
ì‹œê°ì  í”¼ë“œë°±ì´ ìˆëŠ” Motor Imagery BCIë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

---

## ğŸ”— ê´€ë ¨ ê°œë…

- [EEG](../../concepts/eeg)
- [ECoG](../../concepts/ecog)
- [BCI Decoder](../../concepts/bci-decoder)

---

## ğŸ“š ì°¸ê³  ìë£Œ

- Wolpaw & Wolpaw, "Brain-Computer Interfaces"
- BCI2000 documentation
- OpenBCI tutorials

---

## â­ï¸ Next

```{button-ref} day2-future-directions
:color: primary

ë‹¤ìŒ: W8D2 - Future Directions â†’
```
