---
title: "W6D2 - Network Models"
subtitle: "ì‹ ê²½ë§ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ê³¼ ë™ì—­í•™"
---

# W6D2: Network Models

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yujinmin2/yujin_research/blob/main/notebooks/W6D2_NetworkModels.ipynb)

---

## ğŸ“‹ Overview

**í•µì‹¬ ì§ˆë¬¸**: ë‰´ëŸ°ë“¤ì´ ì—°ê²°ë˜ë©´ ì–´ë–¤ ì§‘ë‹¨ì  ë™ì—­í•™ì´ ë‚˜íƒ€ë‚˜ëŠ”ê°€?

ê°œë³„ ë‰´ëŸ°ì˜ ë™ì—­í•™ì„ ë„˜ì–´ **ë„¤íŠ¸ì›Œí¬ ìˆ˜ì¤€**ì˜ í˜„ìƒì„ ì´í•´í•©ë‹ˆë‹¤.

```{mermaid}
flowchart TB
    subgraph ë„¤íŠ¸ì›Œí¬ìœ í˜•
        FF[í”¼ë“œí¬ì›Œë“œ<br/>Feedforward]
        RC[ìˆœí™˜<br/>Recurrent]
        INH[ì–µì œ-í¥ë¶„<br/>E-I Balance]
    end
    
    subgraph í˜„ìƒ
        SYNC[ë™ê¸°í™”<br/>Synchronization]
        OSC[ì§„ë™<br/>Oscillations]
        ATT[ì–´íŠ¸ë™í„°<br/>Attractors]
    end
    
    FF --> SYNC
    RC --> OSC
    INH --> ATT
```

---

## ğŸ¯ Learning Objectives

1. **ì—°ê²° í–‰ë ¬**ë¡œ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° í‘œí˜„
2. **í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬** êµ¬í˜„
3. **ìˆœí™˜ ë„¤íŠ¸ì›Œí¬**ì™€ ì–´íŠ¸ë™í„° ë™ì—­í•™
4. **E-I ê· í˜•** ë„¤íŠ¸ì›Œí¬ ì´í•´

---

## 1. ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°

### 1.1 ì—°ê²° í–‰ë ¬ (Connectivity Matrix)

$$W_{ij} = \text{ë‰´ëŸ° } j \text{ì—ì„œ ë‰´ëŸ° } i \text{ë¡œì˜ ì‹œëƒ…ìŠ¤ ê°€ì¤‘ì¹˜}$$

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import odeint

def create_connectivity(N, p, w_mean=1.0, topology='random'):
    """
    ë„¤íŠ¸ì›Œí¬ ì—°ê²° í–‰ë ¬ ìƒì„±
    
    N : ë‰´ëŸ° ìˆ˜
    p : ì—°ê²° í™•ë¥ 
    topology : 'random', 'ring', 'small_world'
    """
    if topology == 'random':
        W = np.random.randn(N, N) * w_mean
        W = W * (np.random.rand(N, N) < p)
        np.fill_diagonal(W, 0)
        
    elif topology == 'ring':
        W = np.zeros((N, N))
        for i in range(N):
            for j in range(1, int(N*p/2) + 1):
                W[i, (i+j) % N] = w_mean
                W[i, (i-j) % N] = w_mean
    
    return W

# ì‹œê°í™”
fig, axes = plt.subplots(1, 3, figsize=(14, 4))

topologies = ['random', 'ring', 'random']
N = 50

for ax, topo in zip(axes, topologies):
    W = create_connectivity(N, p=0.2, topology=topo)
    im = ax.imshow(W, cmap='RdBu_r', aspect='auto', vmin=-2, vmax=2)
    ax.set_xlabel('Pre-synaptic')
    ax.set_ylabel('Post-synaptic')
    ax.set_title(f'{topo.capitalize()} Network\n(N={N}, p=0.2)')

plt.colorbar(im, ax=axes[-1], label='Weight')
plt.tight_layout()
plt.show()
```

### 1.2 ë„¤íŠ¸ì›Œí¬ í†µê³„

| ì§€í‘œ | ì •ì˜ | ì˜ë¯¸ |
|------|------|------|
| **ì—°ê²° í™•ë¥ ** | $p$ | ë‘ ë‰´ëŸ°ì´ ì—°ê²°ë  í™•ë¥  |
| **í‰ê·  ì°¨ìˆ˜** | $k = pN$ | í‰ê·  ì—°ê²° ìˆ˜ |
| **í´ëŸ¬ìŠ¤í„°ë§ ê³„ìˆ˜** | $C$ | ì´ì›ƒ ê°„ ì—°ê²° ë°€ë„ |
| **ê²½ë¡œ ê¸¸ì´** | $L$ | í‰ê·  ìµœë‹¨ ê²½ë¡œ |

---

## 2. í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬

### 2.1 ê°œë…

ì…ë ¥ì—ì„œ ì¶œë ¥ìœ¼ë¡œ ë‹¨ë°©í–¥ ì „íŒŒ:

```{mermaid}
flowchart LR
    subgraph Input
        I1[â—]
        I2[â—]
        I3[â—]
    end
    
    subgraph Hidden
        H1[â—]
        H2[â—]
    end
    
    subgraph Output
        O1[â—]
    end
    
    I1 --> H1
    I1 --> H2
    I2 --> H1
    I2 --> H2
    I3 --> H1
    I3 --> H2
    H1 --> O1
    H2 --> O1
```

### 2.2 ìŠ¤íŒŒì´í‚¹ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬

```python
def simulate_feedforward_snn(input_spikes, W, duration=100, dt=0.1,
                              tau_m=20, V_th=-55, V_reset=-70, E_L=-70):
    """
    ìŠ¤íŒŒì´í‚¹ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬
    
    input_spikes : (N_in, T) ì…ë ¥ ìŠ¤íŒŒì´í¬ ë°°ì—´
    W : (N_out, N_in) ê°€ì¤‘ì¹˜ í–‰ë ¬
    """
    N_out, N_in = W.shape
    T = int(duration / dt)
    
    V = np.ones((N_out, T)) * E_L
    spikes = np.zeros((N_out, T))
    
    for t in range(1, T):
        # ì‹œëƒ…ìŠ¤ ì…ë ¥
        I_syn = W @ input_spikes[:, min(t, input_spikes.shape[1]-1)]
        
        # LIF ë™ì—­í•™
        dV = (-(V[:, t-1] - E_L) + I_syn * 10) / tau_m * dt
        V[:, t] = V[:, t-1] + dV
        
        # ë°œí™” ì²´í¬
        fired = V[:, t] >= V_th
        spikes[fired, t] = 1
        V[fired, t] = V_reset
    
    return V, spikes

# ì˜ˆì‹œ: 3ì¸µ ë„¤íŠ¸ì›Œí¬
N_layers = [10, 20, 5]
np.random.seed(42)

# ì…ë ¥ ìŠ¤íŒŒì´í¬ ìƒì„±
T = 500
input_spikes = (np.random.rand(N_layers[0], T) < 0.05).astype(float)

# ê°€ì¤‘ì¹˜
W1 = np.random.randn(N_layers[1], N_layers[0]) * 0.5
W2 = np.random.randn(N_layers[2], N_layers[1]) * 0.5

# ìˆœì°¨ ì‹œë®¬ë ˆì´ì…˜
V1, spikes1 = simulate_feedforward_snn(input_spikes, W1)
V2, spikes2 = simulate_feedforward_snn(spikes1, W2)

# ë˜ìŠ¤í„° í”Œë¡¯
fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)

for i, (spk, name, N) in enumerate([(input_spikes, 'Input', N_layers[0]),
                                      (spikes1, 'Hidden', N_layers[1]),
                                      (spikes2, 'Output', N_layers[2])]):
    for n in range(min(N, 20)):
        spike_times = np.where(spk[n])[0] * 0.1
        axes[i].scatter(spike_times, np.ones_like(spike_times) * n, 
                       s=2, c='black')
    axes[i].set_ylabel(f'{name}\n(N={N})')
    axes[i].set_ylim(-0.5, min(N, 20) - 0.5)

axes[-1].set_xlabel('Time (ms)')
plt.suptitle('Feedforward Spiking Network', fontsize=14)
plt.tight_layout()
plt.show()
```

---

## 3. ìˆœí™˜ ë„¤íŠ¸ì›Œí¬ (Recurrent Networks)

### 3.1 Rate-based ìˆœí™˜ ë„¤íŠ¸ì›Œí¬

$$\tau \frac{dr_i}{dt} = -r_i + f\left(\sum_j W_{ij} r_j + I_i\right)$$

### 3.2 ì–´íŠ¸ë™í„° ë™ì—­í•™

```python
def simulate_rate_rnn(W, I_ext, duration=500, dt=1, tau=20):
    """
    Rate-based ìˆœí™˜ ì‹ ê²½ë§
    """
    N = W.shape[0]
    T = int(duration / dt)
    
    r = np.zeros((N, T))
    r[:, 0] = np.random.rand(N) * 0.1
    
    for t in range(1, T):
        # ì´ ì…ë ¥
        h = W @ r[:, t-1] + I_ext
        # í™œì„±í™” í•¨ìˆ˜ (ì‹œê·¸ëª¨ì´ë“œ)
        r_inf = 1 / (1 + np.exp(-h))
        # ë™ì—­í•™
        dr = (-r[:, t-1] + r_inf) / tau * dt
        r[:, t] = r[:, t-1] + dr
    
    return r

# Hopfield ë„¤íŠ¸ì›Œí¬ (ì–´íŠ¸ë™í„°)
N = 100
n_patterns = 3

# ì €ì¥í•  íŒ¨í„´ (binary)
patterns = np.sign(np.random.randn(n_patterns, N))

# Hebbian í•™ìŠµìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì„¤ì •
W = np.zeros((N, N))
for p in patterns:
    W += np.outer(p, p)
W = W / n_patterns
np.fill_diagonal(W, 0)

# ì†ìƒëœ íŒ¨í„´ìœ¼ë¡œ ì‹œì‘
noisy_pattern = patterns[0].copy()
noise_idx = np.random.choice(N, size=int(N*0.3), replace=False)
noisy_pattern[noise_idx] *= -1

# ì‹œë®¬ë ˆì´ì…˜
I_ext = noisy_pattern * 0.5
r = simulate_rate_rnn(W * 0.1, I_ext, duration=200)

# íŒ¨í„´ ë³µì› ì‹œê°í™”
fig, axes = plt.subplots(2, 2, figsize=(12, 8))

# ì›ë˜ íŒ¨í„´
axes[0, 0].imshow(patterns[0].reshape(10, 10), cmap='RdBu_r', aspect='auto')
axes[0, 0].set_title('Original Pattern')
axes[0, 0].axis('off')

# ì†ìƒëœ íŒ¨í„´
axes[0, 1].imshow(noisy_pattern.reshape(10, 10), cmap='RdBu_r', aspect='auto')
axes[0, 1].set_title('Noisy Input (30% corrupted)')
axes[0, 1].axis('off')

# ë³µì›ëœ íŒ¨í„´
recovered = np.sign(r[:, -1] - 0.5)
axes[1, 0].imshow(recovered.reshape(10, 10), cmap='RdBu_r', aspect='auto')
axes[1, 0].set_title('Recovered Pattern')
axes[1, 0].axis('off')

# í™œë™ ë³€í™”
overlap = [np.dot(patterns[0], r[:, t]) / N for t in range(r.shape[1])]
axes[1, 1].plot(overlap, 'b-', linewidth=2)
axes[1, 1].set_xlabel('Time')
axes[1, 1].set_ylabel('Overlap with Pattern')
axes[1, 1].set_title('Pattern Retrieval Dynamics')
axes[1, 1].axhline(y=1, color='red', linestyle='--', label='Perfect')
axes[1, 1].legend()

plt.suptitle('Hopfield Network: Attractor Dynamics', fontsize=14)
plt.tight_layout()
plt.show()
```

---

## 4. E-I ê· í˜• ë„¤íŠ¸ì›Œí¬

### 4.1 ê°œë…

í¥ë¶„ì„±(E)ê³¼ ì–µì œì„±(I) ë‰´ëŸ°ì˜ **ê· í˜•**ì´ ë„¤íŠ¸ì›Œí¬ ë™ì—­í•™ì˜ í•µì‹¬

```{mermaid}
flowchart TB
    E[í¥ë¶„ì„± ë‰´ëŸ°<br/>Excitatory] <--> |í¥ë¶„| I[ì–µì œì„± ë‰´ëŸ°<br/>Inhibitory]
    I --> |ì–µì œ| E
    E --> |í¥ë¶„| E
    
    style E fill:#3498db
    style I fill:#e74c3c
```

### 4.2 E-I ë„¤íŠ¸ì›Œí¬ ì‹œë®¬ë ˆì´ì…˜

```python
def simulate_ei_network(N_E=80, N_I=20, duration=500, dt=0.1):
    """
    E-I ê· í˜• ë„¤íŠ¸ì›Œí¬
    """
    N = N_E + N_I
    T = int(duration / dt)
    
    # ì—°ê²° ê°€ì¤‘ì¹˜
    W = np.zeros((N, N))
    
    # Eâ†’E, Eâ†’I (í¥ë¶„ì„±)
    W[:, :N_E] = np.random.rand(N, N_E) * 0.3 * (np.random.rand(N, N_E) < 0.2)
    
    # Iâ†’E, Iâ†’I (ì–µì œì„±)
    W[:, N_E:] = -np.random.rand(N, N_I) * 1.0 * (np.random.rand(N, N_I) < 0.5)
    
    np.fill_diagonal(W, 0)
    
    # LIF íŒŒë¼ë¯¸í„°
    tau_m = 20
    V_th = -55
    V_reset = -70
    E_L = -70
    
    V = np.ones((N, T)) * E_L
    spikes = np.zeros((N, T))
    
    for t in range(1, T):
        # ì™¸ë¶€ ì…ë ¥ (í¬ì•„ì†¡)
        I_ext = (np.random.rand(N) < 0.01 / dt) * 20
        
        # ì‹œëƒ…ìŠ¤ ì…ë ¥
        I_syn = W @ spikes[:, t-1] * 50
        
        # LIF ë™ì—­í•™
        dV = (-(V[:, t-1] - E_L) + I_ext + I_syn) / tau_m * dt
        V[:, t] = V[:, t-1] + dV
        
        # ë°œí™”
        fired = V[:, t] >= V_th
        spikes[fired, t] = 1
        V[fired, t] = V_reset
    
    return spikes[:N_E], spikes[N_E:], V

# ì‹œë®¬ë ˆì´ì…˜
spikes_E, spikes_I, V = simulate_ei_network()

# ì‹œê°í™”
fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)

# E ë‰´ëŸ° ë˜ìŠ¤í„°
for n in range(min(30, spikes_E.shape[0])):
    spike_times = np.where(spikes_E[n])[0] * 0.1
    axes[0].scatter(spike_times, np.ones_like(spike_times) * n, s=1, c='blue')
axes[0].set_ylabel('E neurons')
axes[0].set_title('E-I Balanced Network')

# I ë‰´ëŸ° ë˜ìŠ¤í„°
for n in range(min(15, spikes_I.shape[0])):
    spike_times = np.where(spikes_I[n])[0] * 0.1
    axes[1].scatter(spike_times, np.ones_like(spike_times) * n, s=1, c='red')
axes[1].set_ylabel('I neurons')

# Population rate
window = 50  # 5ms
rate_E = np.convolve(spikes_E.sum(axis=0), np.ones(window)/window, mode='same') / 0.08 * 1000
rate_I = np.convolve(spikes_I.sum(axis=0), np.ones(window)/window, mode='same') / 0.02 * 1000

t = np.arange(len(rate_E)) * 0.1
axes[2].plot(t, rate_E, 'b-', label='E rate', alpha=0.7)
axes[2].plot(t, rate_I, 'r-', label='I rate', alpha=0.7)
axes[2].set_xlabel('Time (ms)')
axes[2].set_ylabel('Rate (Hz)')
axes[2].legend()

plt.tight_layout()
plt.show()
```

---

## 5. ë„¤íŠ¸ì›Œí¬ ì§„ë™ (Oscillations)

### 5.1 ê°ë§ˆ ì§„ë™ (30-80 Hz)

E-I ìƒí˜¸ì‘ìš©ì—ì„œ ë°œìƒí•˜ëŠ” ë¹ ë¥¸ ì§„ë™

```python
# ì£¼íŒŒìˆ˜ ë¶„ì„
from scipy.signal import welch

rate_total = rate_E + rate_I * 0.2
f, psd = welch(rate_total, fs=10000, nperseg=2048)

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

axes[0].plot(t, rate_total, 'k-', linewidth=0.5)
axes[0].set_xlabel('Time (ms)')
axes[0].set_ylabel('Population Rate')
axes[0].set_title('Network Activity')
axes[0].set_xlim(200, 400)

axes[1].semilogy(f, psd, 'b-')
axes[1].set_xlabel('Frequency (Hz)')
axes[1].set_ylabel('Power')
axes[1].set_title('Power Spectrum')
axes[1].set_xlim(0, 200)
axes[1].axvspan(30, 80, alpha=0.3, color='yellow', label='Gamma band')
axes[1].legend()

plt.tight_layout()
plt.show()
```

---

## ğŸ“ ì‹¤ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: ë™ê¸°í™”
ë„¤íŠ¸ì›Œí¬ ì—°ê²° ê°•ë„ì— ë”°ë¥¸ ë™ê¸°í™” ì •ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

### ë¬¸ì œ 2: Small-World ë„¤íŠ¸ì›Œí¬
Small-world í† í´ë¡œì§€ê°€ ì •ë³´ ì „íŒŒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ì„¸ìš”.

### ë¬¸ì œ 3: E-I ë¹„ìœ¨
E:I ë¹„ìœ¨ì´ ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ì„¸ìš”.

---

## ğŸ”— ê´€ë ¨ ê°œë…

- [Spiking Neural Networks](../../concepts/spiking-nn)
- [Recurrent Networks](../../concepts/recurrent-networks)
- [STDP](../../concepts/stdp)

---

## ğŸ“š ì°¸ê³  ìë£Œ

- Gerstner & Kistler, Chapter 12: Networks
- Dayan & Abbott, Chapter 7
- Brunel (2000): E-I Networks

---

## â­ï¸ Next

```{button-ref} ../week7/day1-supervised-learning
:color: primary

ë‹¤ìŒ: W7D1 - Supervised Learning â†’
```
